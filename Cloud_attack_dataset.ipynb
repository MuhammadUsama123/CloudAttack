{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c03bdd-d11b-44f8-9a6e-ca6a47a65cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ff963b2-4c64-4b62-8471-b8ea2957f902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_dataset(folder_path):\n",
    "    data = []  # To store image data\n",
    "    labels = []  # To store labels\n",
    "    label_names = os.listdir(folder_path)  # Folder names as labels\n",
    "    performance_metrics = []\n",
    "    \n",
    "    for label_id, label_name in enumerate(label_names):\n",
    "        label_folder = os.path.join(folder_path, label_name)\n",
    "        if os.path.isdir(label_folder):\n",
    "            for file_name in os.listdir(label_folder):\n",
    "                file_path = os.path.join(label_folder, file_name)\n",
    "                image = Image.open(file_path).convert('RGB')  # Ensure 3 channels\n",
    "                image_array = np.array(image)\n",
    "                data.append(image_array)\n",
    "                labels.append(label_id)  # Use label_id for numerical labels\n",
    "                \n",
    "    return np.array(data), np.array(labels), label_names, performance_metrics\n",
    "\n",
    "data, labels, label_names,performance_metrics = load_dataset('D:\\CIC_DOS_2017_IMAGES')\n",
    "\n",
    "# Now `data` contains the image data, `labels` contains their corresponding labels, and `label_names` the names of the attack types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b7dd57c-4fbd-4bf6-ad9b-2e7c594379a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc5e02db-8e20-436e-9f7a-19490adafc2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benign_0',\n",
       " 'DDOS_1',\n",
       " 'DOS_Golden_2',\n",
       " 'DOS_Hulk_3',\n",
       " 'DOS_Slowhttptest_4',\n",
       " 'DOS_slowloris_5',\n",
       " 'FTP_Patator_6',\n",
       " 'Heartbleed_7',\n",
       " 'Infiltration_8',\n",
       " 'Portscan_9',\n",
       " 'SSH_Patator_10',\n",
       " 'web_attack_brute_force_11',\n",
       " 'Web_attack_sql_injection_12',\n",
       " 'web_attack_xss_13']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2406a8e7-2787-43d8-98a7-d9018378d7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100541\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffc834-cbd9-4708-adb5-1c944b52ce0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42465cf0-16df-4e77-a79f-08692f13d2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d73aca-1488-4c83-9d0f-4a2bd7c90412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9789516-0a6c-4731-ad87-7953e564b9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the data\n",
    "data_normalized = data / 255.0\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_normalized, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten the data for Logistic Regression\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fce36695-92ec-4171-9256-6881952ec2c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.75      0.62      5412\n",
      "           1       0.83      0.93      0.88      4416\n",
      "           2       0.33      0.02      0.03      2051\n",
      "           3       0.41      0.52      0.46      3311\n",
      "           4       0.41      0.31      0.36      1188\n",
      "           5       0.00      0.00      0.00       121\n",
      "           6       0.00      0.00      0.00        11\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.87      0.64      0.74      3180\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       1.00      0.00      0.01       279\n",
      "          12       0.00      0.00      0.00         5\n",
      "          13       0.00      0.00      0.00       121\n",
      "\n",
      "    accuracy                           0.61     20109\n",
      "   macro avg       0.31      0.23      0.22     20109\n",
      "weighted avg       0.60      0.61      0.58     20109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_flat, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test_flat)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_logistic,zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d023b13e-fb01-42b0-845c-8979027c5a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, ..., 9, 0, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44693de4-38f8-466a-a5fd-5923cc4e9654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1780b8f-aa24-426a-968d-229b1b20647c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5707 - loss: 1.2511 - val_accuracy: 0.6225 - val_loss: 1.0452\n",
      "Epoch 2/10\n",
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6325 - loss: 1.0402 - val_accuracy: 0.6467 - val_loss: 0.9983\n",
      "Epoch 3/10\n",
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: 1.0067 - val_accuracy: 0.6477 - val_loss: 0.9819\n",
      "Epoch 4/10\n",
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6509 - loss: 0.9839 - val_accuracy: 0.6513 - val_loss: 0.9679\n",
      "Epoch 5/10\n",
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6543 - loss: 0.9698 - val_accuracy: 0.6597 - val_loss: 0.9543\n",
      "Epoch 6/10\n",
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.6554 - loss: 0.9610 - val_accuracy: 0.6576 - val_loss: 0.9416\n",
      "Epoch 7/10\n",
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.6607 - loss: 0.9395 - val_accuracy: 0.6534 - val_loss: 0.9459\n",
      "Epoch 8/10\n",
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.6625 - loss: 0.9372 - val_accuracy: 0.6611 - val_loss: 0.9444\n",
      "Epoch 9/10\n",
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.6618 - loss: 0.9302 - val_accuracy: 0.6635 - val_loss: 0.9346\n",
      "Epoch 10/10\n",
      "\u001b[1m2263/2263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6631 - loss: 0.9217 - val_accuracy: 0.6652 - val_loss: 0.9283\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6637 - loss: 0.9321\n",
      "CNN Model Test Accuracy: 0.6608483791351318\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "data_normalized = data / 255.0\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_normalized, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(9, 9, 3)),\n",
    "    Flatten(),  # Ensuring we flatten the output from the convolutional layers before feeding into dense layers\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(14, activation='softmax')  # Adjusted for 14 classes as per your dataset\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_model.fit(X_train, y_train, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "val_loss, val_acc = cnn_model.evaluate(X_test, y_test)\n",
    "print(f\"CNN Model Test Accuracy: {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f17386fe-0640-48b7-a625-a2bd5a4da435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04310a8a-f02b-4345-ac94-f67fa401c1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def load_dataset(folder_path):\n",
    "    data = []  # To store image data\n",
    "    labels = []  # To store labels\n",
    "    label_names = os.listdir(folder_path)  # Folder names as labels\n",
    "    \n",
    "    for label_id, label_name in enumerate(label_names):\n",
    "        label_folder = os.path.join(folder_path, label_name)\n",
    "        if os.path.isdir(label_folder):\n",
    "            for file_name in os.listdir(label_folder):\n",
    "                file_path = os.path.join(label_folder, file_name)\n",
    "                image = Image.open(file_path).convert('RGB')  \n",
    "                image_array = np.array(image)\n",
    "                data.append(image_array)\n",
    "                labels.append(label_id)  \n",
    "                \n",
    "    return np.array(data), np.array(labels), label_names, performance_metrics\n",
    "\n",
    "data, labels, label_names, performance_metrics = load_dataset('D:\\CIC_DOS_2017_IMAGES')\n",
    "label_names_array = np.array(label_names).astype('S')\n",
    "\n",
    "# Save data to HDF5\n",
    "with h5py.File('cloud_attack_data.h5', 'w') as hf:\n",
    "    hf.create_dataset('data', data=data)\n",
    "    hf.create_dataset('labels', data=labels)\n",
    "    hf.create_dataset('label_names', data=label_names_array.astype('S'))\n",
    "    hf.create_dataset('performance_metrics', data = classification_report(y_test, y_pred_logistic,zero_division=0))  # Convert label_names to bytes for storage\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5049fc-7f46-465e-8914-682c623d9e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
